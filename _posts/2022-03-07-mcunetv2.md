---
title: "Bringing deep learning models to microcontrollers"
date: 2022-02-19T18:47:00.000Z
lang: de
categories:
  - blog
tags:
  - tinyML
published: false
---

## CNN auf Microcontrollern

Die jüngste dieser Bemühungen, eine gemeinsame Arbeit von IBM und dem Massachusetts Institute of Technology (MIT), befasst sich mit dem Engpass bei der Speicherkapazität von Faltungsneuronalen Netzen (CNN), einer Deep-Learning-Architektur, die besonders für Computer-Vision-Anwendungen wichtig ist. Das in einem auf der NeurIPS-Konferenz 2021 vorgestellten Papier beschriebene Modell heißt MCUNetV2 und kann CNNs auf Mikrocontrollern mit geringem Speicherbedarf und niedrigem Stromverbrauch ausführen.

Das Problem bei Pruning-Methoden ist, dass sie den Speicherengpass der neuronalen Netze nicht beheben. Standardimplementierungen von Deep-Learning-Bibliotheken erfordern, dass eine gesamte Netzwerkschicht und Aktivierungskarten in den Speicher geladen werden. Leider nehmen klassische Optimierungsmethoden keine nennenswerten Änderungen an den frühen Schichten des Netzes vor, insbesondere bei Faltungsneuronalen Netzen.

Dies führt zu einem Ungleichgewicht in der Größe der verschiedenen Schichten des Netzes und zu einem "Memory-Peak"-Problem: Auch wenn das Netz nach dem Pruning kleiner wird, muss das Gerät, auf dem es läuft, so viel Speicher wie die größte Schicht haben. In MobileNetV2, einem beliebten TinyML-Modell, haben die ersten Schichtenblöcke eine Speicherspitze, die etwa 1,4 Megabyte erreicht, während die späteren Schichten einen sehr geringen Speicherbedarf haben. Um das Modell auszuführen, benötigt ein Gerät so viel Speicher wie der Spitzenwert des Modells. Da die meisten MCUs nicht mehr als ein paar hundert Kilobyte Speicher haben, können sie die Standardversion von MobileNetV2 nicht ausführen.

Patch-basierte Inferenz mit MCUNetV2
Um den Speicherengpass von faltungsbasierten neuronalen Netzen zu beheben, haben die Forscher MCUNetV2 entwickelt, eine Deep-Learning-Architektur, die ihre Speicherbandbreite an die Grenzen von Mikrocontrollern anpassen kann. MCUNetV2 baut auf einer früheren Arbeit derselben Gruppe auf, die auf der NeurIPS 2020-Konferenz angenommen und vorgestellt wurde.

Die Hauptidee hinter MCUNetV2 ist die "Patch-basierte Inferenz", eine Technik, die den Speicherbedarf von CNNs reduziert, ohne ihre Genauigkeit zu beeinträchtigen. Anstatt eine gesamte Schicht des neuronalen Netzes in den Speicher zu laden, lädt und berechnet MCUNetV2 zu jedem Zeitpunkt einen kleineren Bereich - einen "Patch" - der Schicht. Anschließend durchläuft es die gesamte Schicht Patch für Patch und kombiniert die Werte, bis es die Aktivierungen für die gesamte Schicht berechnet.

Da MCUNetV2 jeweils nur ein Neuronenfeld speichern muss, verringert es die Speicherspitze erheblich, ohne die Auflösung oder die Parameter des Modells zu reduzieren. Die Experimente der Forscher zeigen, dass MCUNetV2 die Speicherspitze um das Achtfache reduzieren kann.

MCUNetV2 reduziert die Speicherspitze von Deep-Learning-Modellen um das bis zu 8-fache
MCUNetV2 reduziert die Speicherspitze von Deep-Learning-Modellen um das bis zu 8-fache
Die Vorteile der speicherschonenden patchbasierten Inferenz gehen mit einem Kompromiss beim Rechenaufwand einher. Die Forscher von MIT und IBM fanden heraus, dass die Gesamtberechnung des Netzwerks in verschiedenen Architekturen um 10 bis 17 Prozent ansteigen könnte, was für Mikrocontroller mit geringer Leistung nicht geeignet ist.

Um diese Grenze zu überwinden, verteilten die Forscher das "rezeptive Feld" der verschiedenen Blöcke des Netzwerks neu. Bei CNNs ist das rezeptive Feld der Bereich des Bildes, der zu einem bestimmten Zeitpunkt verarbeitet wird. Größere rezeptive Felder erfordern größere Felder und Überschneidungen zwischen den Feldern, was zu einem höheren Berechnungsaufwand führt. Durch die Verkleinerung der rezeptiven Felder der ersten Blöcke des Netzes und die Vergrößerung der rezeptiven Felder in den späteren Phasen konnten die Forscher den Rechenaufwand um mehr als zwei Drittel reduzieren.

Die Umverteilung der rezeptiven Felder hilft, den Rechenaufwand von MCUNetV2 um mehr als zwei Drittel zu reduzieren
Die Neuverteilung der rezeptiven Felder trägt dazu bei, den Rechenaufwand von MCUNetV2 um mehr als zwei Drittel zu verringern
Schließlich stellten die Forscher fest, dass die Anpassungen von MCUNetV2 weitgehend von der ML-Modellarchitektur, der Anwendung sowie der Speicher- und Speicherkapazität des Zielgeräts abhängen. Um eine manuelle Abstimmung des Deep-Learning-Modells für jedes Gerät und jede Anwendung zu vermeiden, verwendeten die Forscher die "neuronale algorithmische Suche", einen Prozess, der maschinelles Lernen zur automatischen Optimierung der Architektur des neuronalen Netzwerks und der Inferenzplanung nutzt.

Die Forscher testeten die Deep-Learning-Architektur in verschiedenen Anwendungen auf mehreren Mikrocontroller-Modellen mit geringer Speicherkapazität. Die Ergebnisse zeigen, dass MCUNetV2 andere TinyML-Techniken übertrifft und eine höhere Genauigkeit bei der Bildklassifizierung und Objekterkennung bei geringerem Speicherbedarf und niedrigeren Latenzzeiten erreicht.

Die Forscher zeigen MCUNetV2 in Aktion anhand von Echtzeit-Personenerkennung, visuellen Weckwörtern und Gesichts-/Maskenerkennung.


## Speicherbedarf von CNN Netzen

## Chancen - Nachhaltigkeit

## Ausblick